---
output:
  pdf_document: default
  officedown::rdocx_document:
    mapstyles:
      Normal: First Paragraph
    reference_docx: reference.docx
    tables: 
      width: 1.0
  html_document:
    df_print: paged
bibliography: benchmarking_references.bib
csl: biomed-central.csl
urlcolor: blue
---

```{r setup_bench, include=FALSE}
# options
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE, 
  warning = FALSE,
  out.width = "100%"
)
```

```{r libraries_globals}
# libraries
library(plyr)
library(immunoCluster)
library(Spectre)
library(cytofkit)
library(flowCore)
library(tidytof)
library(tidyverse)
library(microbenchmark)
library(patchwork)
filter <- dplyr::filter
count <- dplyr::count
summarize <- dplyr::summarize

# source benchmarking functions 
source(here::here("manuscript", "benchmarking", "benchmarking_functions.R"))
source(here::here("manuscript", "benchmarking", "benchmarking_script.R"))

# globals
largest_file_name <- FALSE
machine <- "excalibur"
num_repeats <- 10L
charizard <- 
  c(
    "base" = "#207394", 
    "tidytof" = "#cd5241", 
    "flowcore" = "#eeb45a", 
    "cytofkit" = "#833118", 
    "spectre" = "#837b92", 
    "immunocluster" = "#FFEEB0"
  )
engine_labels <- 
  c(
    "base" = "base", 
    "tidytof" = "tidytof", 
    "flowcore" = "flowCore", 
    "cytofkit" = "cytofkit",
    "spectre" = "Spectre", 
    "immunocluster" = "immunoCluster"
  )

# which benchmarking sections to run from scratch
set_up_csvs <- FALSE
run_io <- TRUE
run_downsample <- TRUE
run_preprocess <- TRUE
run_tsne <- TRUE
run_pca <- TRUE
run_umap <- TRUE
run_cluster <- TRUE
run_extract <- TRUE
run_memory <- TRUE
run_style <- TRUE

# should I print the large versions of each plot
print_large <- FALSE

# should messages be printed during benchmarking
verbose <- FALSE


# file paths 
if (machine == "galaxia") { 
  base_path <- file.path("~", "Box", "Tim", "Lab", "Data")
} else {
  base_path <- file.path("~", "Desktop", "data")
}
ddpr_path <-
  file.path(base_path, "DDPR_Data")

csv_path <- 
  file.path(base_path, "DDPR_Data_csv")

mini_path <- 
  file.path(base_path, "DDPR_Data_mini")

ddpr_files <- 
  dir(ddpr_path, full.names = TRUE)

spectre_path <- 
  file.path(base_path, "tidytof_benchmarking") %>% 
  dir(full.names = TRUE) %>% 
  purrr::pluck(1)

```

```{r run_all_benchmarking, warning = FALSE, message = TRUE}
# run all benchmarking from scratch 
benchmark_master(
  set_up_csvs = set_up_csvs,
  run_io = run_io,
  run_downsample = run_downsample,
  run_preprocess = run_preprocess,
  run_tsne = run_tsne,
  run_pca = run_pca,
  run_umap = run_umap,
  run_cluster = run_cluster,
  run_extract = run_extract,
  run_memory = run_memory,
  run_style = run_style,
  num_repeats = num_repeats,
  num_channels = 10,
  base_path = base_path, 
  verbose = verbose
)
filter <- dplyr::filter
count <- dplyr::count
summarize <- dplyr::summarize
```



```{r store_all_file_paths}
# find file paths corresponding to the highest number of repeats 
in_out_paths <- 
  tibble(
    process = 
      c("fcs", "csv", "downsampling", "preprocessing", "tsne", "pca", "umap",  "flowsom", "extraction"), 
    pattern = 
      paste0(
        c(
          "io_benchmarking_speed_", 
          "io_benchmarking_speed_csv_", 
          "downsample_benchmarking_speed_", 
          "preprocess_benchmarking_speed_", 
          "tsne_benchmarking_speed_", 
          "pca_benchmarking_speed_", 
          "umap_benchmarking_speed_", 
          "flowsom_benchmarking_speed_", 
          "extract_benchmarking_speed_"
        ), 
        "[:digit:]+"
      ), 
    largest_size = 
      map_int(
        .x = pattern, 
        .f = ~
          here::here("manuscript", "benchmarking") %>% 
          dir() %>% 
          str_extract(.x) %>% 
          na.omit() %>% 
          str_extract("[:digit:]+$") %>% 
          as.integer() %>% 
          unique() %>% 
          sort(decreasing = TRUE) %>% 
          pluck(1), 
      ), 
    file_name = 
      paste0(
        str_replace(
          string = pattern, pattern = "\\[.+\\]\\+", 
          as.character(largest_size)
        ),
        ".rds"
      )
  )

```


```{r io_file_names}
if (largest_file_name) { 
# file paths
file_name <- 
  in_out_paths %>% 
  filter(process == "fcs") %>% 
  pull(file_name)

file_name_csv <- 
  in_out_paths %>% 
  filter(process == "csv") %>% 
  pull(file_name)
} else {
  file_name <- 
    in_out_paths %>% 
    filter(process == "fcs") %>% 
    pull(pattern) %>% 
    str_replace("\\[\\:digit\\:\\]\\+", as.character(num_repeats)) %>% 
    str_c(., ".rds")
  
  file_name_csv <- 
    in_out_paths %>% 
    filter(process == "csv") %>% 
    pull(pattern) %>% 
    str_replace("\\[\\:digit\\:\\]\\+", as.character(num_repeats)) %>% 
    str_c(., ".rds")
}
```



```{r visualize_io_result, message = FALSE}
io_benchmarking <- 
  read_rds(file = here::here("manuscript", "benchmarking", file_name))

engines <- 
  io_benchmarking %>% 
  select(io_benchmarks) %>% 
  unnest(io_benchmarks) %>% 
  #mutate(engine = if_else(engine == "base", "flowcore", engine)) %>% 
  pull(engine) %>% 
  unique()

num_engines <- length(engines)

my_palette <- charizard[which(names(charizard) %in% engines)]

max_cells <- max(io_benchmarking$num_cells)
width <- max_cells * 0.05
  

# make a plot to summarize 
io_speed_plot <- 
  io_benchmarking %>% 
  select(num_files, num_cells, io_benchmarks) %>% 
  unnest(cols = io_benchmarks) %>% 
  #mutate(engine = if_else(engine == "base", "flowcore", engine)) %>% 
  group_by(num_files, num_cells, engine) %>% 
  dplyr::summarize(
    mean_time = median(time), 
    max_time = quantile(time, 0.75), 
    min_time = quantile(time, 0.25)
  ) %>% 
  dplyr::ungroup() %>% 
  ggplot(
    aes(
      x = num_cells, 
      y = mean_time, 
      fill = engine, 
      color = engine, 
      ymin = min_time, 
      ymax = max_time
    )
  ) + 
  geom_errorbar(width = width) + 
  geom_line(aes(group = engine)) + 
  geom_point(shape = 21, size = 2, color = "black") + 
  scale_x_continuous(labels = scales::label_scientific(digits = 1)) + 
  scale_fill_manual(values = my_palette) + 
  scale_color_manual(values = my_palette) +
  theme_bw() + 
  labs(
    subtitle = "FCS reader",
    x = "Number of cells", 
    y = "Time (seconds)", 
    fill = NULL, 
    color = NULL
  )

if (print_large) {
  io_speed_plot
}

io_speed_plot %>% 
  ggsave(
    filename = 
      here::here(
        "manuscript", 
        "benchmarking", 
        str_replace(file_name, ".rds", ".pdf")
      ), 
    device = "pdf", 
    width = 5, 
    height = 3
  )

```


```{r visualize_io_result_csv, message = FALSE}
io_benchmarking_csv <- 
  read_rds(file = here::here("manuscript", "benchmarking", file_name_csv))

engines <- 
  io_benchmarking_csv %>% 
  select(io_benchmarks) %>% 
  unnest(io_benchmarks) %>% 
  pull(engine) %>% 
  unique()

my_palette <- charizard[which(names(charizard) %in% engines)]

max_cells <- max(io_benchmarking_csv$num_cells)
width <- max_cells * 0.05

# visualize speed benchmarking results
io_speed_plot_csv <- 
  io_benchmarking_csv %>% 
  select(num_files, num_cells, io_benchmarks) %>% 
  unnest(cols = io_benchmarks) %>% 
  group_by(num_files, num_cells, engine) %>% 
  summarize(
    mean_time = median(time), 
    max_time = quantile(time, 0.75), 
    min_time = quantile(time, 0.25)
  ) %>% 
  ungroup() %>% 
  ggplot(
    aes(
      x = num_cells, 
      y = mean_time, 
      fill = engine, 
      color = engine, 
      ymin = min_time, 
      ymax = max_time
    )
  ) + 
  geom_errorbar(width = width) + 
  geom_line(aes(group = engine)) + 
  geom_point(shape = 21, size = 2, color = "black") + 
  scale_x_continuous(labels = scales::label_scientific(digits = 1)) + 
  scale_fill_manual(values = my_palette, labels = engine_labels) + 
  scale_color_manual(values = my_palette, labels = engine_labels) +
  theme_bw() + 
  labs(
    subtitle = "CSV reader",
    x = "Number of cells", 
    y = "Time (seconds)", 
    fill = NULL, 
    color = NULL
  )

if (print_large) {
  io_speed_plot_csv
}

io_speed_plot_csv %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", str_replace(file_name_csv, ".rds", ".pdf")), 
    device = "pdf", 
    width = 5, 
    height = 3
  )
```


```{r downsample_file_names}
if (largest_file_name) { 
  file_name <- 
    in_out_paths %>% 
    filter(process == "downsampling") %>% 
    pull(file_name)
} else {
  file_name <- 
    in_out_paths %>% 
    filter(process == "downsampling") %>% 
    pull(pattern) %>% 
    str_replace("\\[\\:digit\\:\\]\\+", as.character(num_repeats)) %>% 
    str_c(., ".rds")
}

```


```{r visualize_downsampling_result, message = FALSE}
downsample_benchmarking <- 
  read_rds(file = here::here("manuscript", "benchmarking", file_name))

max_cells <- max(downsample_benchmarking$num_cells)
width <- max_cells * 0.05

# make a plot to summarize 
downsample_speed_plot <- 
  downsample_benchmarking %>% 
  select(num_files, num_cells, downsample_benchmarks) %>% 
  unnest(cols = downsample_benchmarks) %>% 
  group_by(num_files, num_cells, engine) %>% 
  summarize(
    mean_time = median(time), 
    max = max(time), 
    min = min(time),
    sd_time = sd(time),
    max_time = quantile(time, 0.75), 
    min_time = quantile(time, 0.25)
  ) %>%
  ungroup() %>%
  ggplot(
    aes(
      x = num_cells, 
      y = mean_time, 
      fill = engine, 
      color = engine, 
      ymin = min_time, 
      ymax = max_time
    )
  ) + 
  geom_errorbar(width = width) +
  geom_line(aes(group = engine)) + 
  geom_point(shape = 21, size = 2, color = "black") + 
  scale_x_continuous(labels = scales::label_scientific(digits = 1)) + 
  scale_color_manual(values = charizard, labels = engine_labels) + 
  scale_fill_manual(values = charizard, labels = engine_labels) +
  theme_bw() + 
  labs(
    subtitle = "Downsampling",
    x = "Number of cells", 
    y = "Time (seconds)", 
    fill = NULL, 
    color = NULL
  )

if (print_large) {
  downsample_speed_plot
}

downsample_speed_plot %>% 
  ggsave(
    filename = 
      here::here(
        "manuscript", 
        "benchmarking", 
        str_replace(file_name, ".rds", ".pdf")
      ), 
    device = "pdf", 
    width = 5, 
    height = 3
  )
```


```{r preprocess_file_name}
file_name <- 
  in_out_paths %>% 
  filter(process == "preprocessing") %>% 
  pull(file_name)
```


```{r visualize_benchmarking_result, message = FALSE}
preprocess_benchmarking <- 
  read_rds(file = here::here("manuscript", "benchmarking", file_name))

max_cells <- max(preprocess_benchmarking$num_cells)
width <- max_cells * 0.05

# make a plot to summarize 
preprocess_speed_plot <- 
  preprocess_benchmarking %>% 
  select(num_files, num_cells, preprocess_benchmarks) %>% 
  unnest(cols = preprocess_benchmarks) %>% 
  group_by(num_files, num_cells, engine) %>% 
  summarize(
    mean_time = median(time), 
    max_time = quantile(time, 0.75), 
    min_time = quantile(time, 0.25)
  ) %>% 
  ungroup() %>% 
  ggplot(
    aes(
      x = num_cells, 
      y = mean_time, 
      fill = engine, 
      color = engine, 
      ymin = min_time, 
      ymax = max_time
    )
  ) + 
  geom_errorbar(width = width) +
  geom_line(aes(group = engine)) + 
  geom_point(
    shape = 21, 
    size = 2, 
    color = "black", 
    position = position_dodge(width = 15000)
  ) + 
  scale_x_continuous(labels = scales::label_scientific(digits = 1)) + 
  scale_color_manual(values = charizard, labels = engine_labels) + 
  scale_fill_manual(values = charizard, labels = engine_labels) + 
  theme_bw() + 
  labs(
    subtitle = "Preprocessing",
    x = "Number of cells", 
    y = "Time (seconds)", 
    fill = NULL, 
    color = NULL
  )

if (print_large) {
  preprocess_speed_plot
}

preprocess_speed_plot %>% 
  ggsave(
    filename = 
      here::here(
        "manuscript", 
        "benchmarking", 
        str_replace(file_name, ".rds", ".pdf")
      ), 
    device = "pdf", 
    width = 5, 
    height = 3
  )
```



```{r dimensionality_reduction_file_names}
file_name_tsne <- 
  in_out_paths %>% 
  filter(process == "tsne") %>% 
  pull(file_name)

file_name_pca <- 
  in_out_paths %>% 
  filter(process == "pca") %>% 
  pull(file_name)

file_name_umap <- 
  in_out_paths %>% 
  filter(process == "umap") %>% 
  pull(file_name)
```



```{r visualize_tsne_result, message = FALSE}
tsne_benchmark <- 
  read_rds(file = here::here("manuscript", "benchmarking", file_name_tsne))

max_cells <- max(tsne_benchmark$num_cells)
width <- max_cells * 0.05
  
engines <- 
  tsne_benchmark %>% 
  select(tsne_benchmarks) %>% 
  unnest(tsne_benchmarks) %>% 
  pull(engine) %>% 
  unique()

num_engines <- length(engines)

my_palette <- charizard[which(names(charizard) %in% engines)]

# make a plot to summarize 
tsne_speed_plot <- 
  tsne_benchmark %>%
  select(num_cells, tsne_benchmarks) %>% 
  unnest(cols = tsne_benchmarks) %>% 
  group_by(num_cells, engine) %>% 
  summarize(
    mean_time = mean(time), 
    max_time = max(time), 
    min_time = min(time)
  ) %>% 
  ungroup() %>% 
  ggplot(
    aes(
      x = num_cells, 
      y = mean_time, 
      fill = engine, 
      color = engine, 
      ymin = min_time, 
      ymax = max_time
    )
  ) + 
  geom_errorbar(width = width) + 
  geom_line(aes(group = engine)) + 
  geom_point(shape = 21, size = 2, color = "black") + 
  scale_x_continuous(labels = scales::label_scientific(digits = 1)) + 
  scale_color_manual(values = my_palette, labels = engine_labels) + 
  scale_fill_manual(values = my_palette, labels = engine_labels) +
  theme_bw() + 
  labs(
    subtitle = "tSNE",
    x = "Number of cells", 
    y = "Time (seconds)", 
    fill = NULL, 
    color = NULL
  )

if (print_large) {
  tsne_speed_plot
}

tsne_speed_plot %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", str_replace(file_name_tsne, ".rds", ".pdf")), 
    device = "pdf", 
    width = 5, 
    height = 3
  )

```



```{r visualize_pca_result, message = FALSE}
pca_benchmark <- 
  read_rds(file = here::here("manuscript", "benchmarking", file_name_pca))

max_cells <- max(pca_benchmark$num_cells)
width <- max_cells * 0.05
  
engines <- 
  pca_benchmark %>% 
  select(pca_benchmarks) %>% 
  unnest(pca_benchmarks) %>% 
  pull(engine) %>% 
  unique()

num_engines <- length(engines)

my_palette <- charizard[which(names(charizard) %in% engines)]

# make a plot to summarize 
pca_speed_plot <- 
  pca_benchmark %>%
  select(num_cells, pca_benchmarks) %>% 
  unnest(cols = pca_benchmarks) %>% 
  group_by(num_cells, engine) %>% 
  summarize(
    mean_time = median(time), 
    max_time = quantile(time, 0.75), 
    min_time = quantile(time, 0.25)
  ) %>% 
  ungroup() %>% 
  ggplot(
    aes(
      x = num_cells, 
      y = mean_time, 
      fill = engine, 
      color = engine, 
      ymin = min_time, 
      ymax = max_time
    )
  ) + 
  geom_errorbar(width = width) + 
  geom_line(aes(group = engine)) + 
  geom_point(shape = 21, size = 2, color = "black") + 
  scale_x_continuous(labels = scales::label_scientific(digits = 1)) + 
  scale_color_manual(values = my_palette, labels = engine_labels) + 
  scale_fill_manual(values = my_palette, labels = engine_labels) +
  theme_bw() + 
  labs(
    subtitle = "PCA",
    x = "Number of cells", 
    y = "Time (seconds)", 
    fill = NULL, 
    color = NULL
  )

if (print_large) {
  pca_speed_plot
}

pca_speed_plot %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", str_replace(file_name_pca, ".rds", ".pdf")), 
    device = "pdf", 
    width = 5, 
    height = 3
  )

```


```{r visualize_umap_result, message = FALSE}
umap_benchmark <- 
  read_rds(file = here::here("manuscript", "benchmarking", file_name_umap))

max_cells <- max(umap_benchmark$num_cells)
width <- max_cells * 0.05
  
engines <- 
  umap_benchmark %>% 
  select(umap_benchmarks) %>% 
  unnest(umap_benchmarks) %>% 
  pull(engine) %>% 
  unique()

num_engines <- length(engines)

my_palette <- charizard[which(names(charizard) %in% engines)]

# make a plot to summarize 
umap_speed_plot <- 
  umap_benchmark %>%
  select(num_cells, umap_benchmarks) %>% 
  unnest(cols = umap_benchmarks) %>% 
  group_by(num_cells, engine) %>% 
  summarize(
    mean_time = mean(time), 
    max_time = max(time), 
    min_time = min(time)
  ) %>% 
  ungroup() %>% 
  ggplot(
    aes(
      x = num_cells, 
      y = mean_time, 
      fill = engine, 
      color = engine, 
      ymin = min_time, 
      ymax = max_time
    )
  ) + 
  geom_errorbar(width = width) + 
  geom_line(aes(group = engine)) + 
  geom_point(shape = 21, size = 2, color = "black") + 
  scale_x_continuous(labels = scales::label_scientific(digits = 1)) + 
  scale_color_manual(values = my_palette, labels = engine_labels) + 
  scale_fill_manual(values = my_palette, labels = engine_labels) +
  theme_bw() + 
  labs(
    subtitle = "UMAP",
    x = "Number of cells", 
    y = "Time (seconds)", 
    fill = NULL, 
    color = NULL
  )

if (print_large) {
  umap_speed_plot
}

umap_speed_plot %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", str_replace(file_name_umap, ".rds", ".pdf")), 
    device = "pdf", 
    width = 5, 
    height = 3
  )
```



```{r flowsom_file_names}
file_name <- 
  in_out_paths %>% 
  filter(process == "flowsom") %>% 
  pull(file_name)
```


```{r visualize_flowsom_result, message = FALSE}
cluster_benchmarking <-
  read_rds(file = here::here("manuscript", "benchmarking", file_name))

max_cells <- max(cluster_benchmarking$num_cells)
width <- max_cells * 0.05
  

engines <- 
  cluster_benchmarking %>% 
  select(cluster_benchmarks) %>% 
  unnest(cluster_benchmarks) %>% 
  pull(engine) %>% 
  unique()

num_engines <- length(engines)

my_palette <- charizard[which(names(charizard) %in% engines)]

flowsom_speed_plot <- 
  cluster_benchmarking %>% 
  select(num_files, num_cells, cluster_benchmarks) %>% 
  unnest(cols = cluster_benchmarks) %>% 
  group_by(num_files, num_cells, engine) %>% 
  summarize(
    mean_time = median(time), 
    max_time = quantile(time, 0.75), 
    min_time = quantile(time, 0.25)
  ) %>% 
  ungroup() %>% 
  ggplot(
    aes(
      x = num_cells, 
      y = mean_time, 
      fill = engine, 
      color = engine, 
      ymin = min_time, 
      ymax = max_time
    )
  ) + 
  geom_errorbar(width = width) + 
  geom_line() +
  geom_point(shape = 21, size = 2, color = "black") + 
  scale_x_continuous(labels = scales::label_scientific(digits = 1)) + 
  scale_fill_manual(values = my_palette, labels = engine_labels) + 
  scale_color_manual(values = my_palette, labels = engine_labels) +
  theme_bw() + 
  labs(
    subtitle = "FlowSOM",
    x = "Number of cells", 
    y = "Time (seconds)", 
    fill = NULL, 
    color = NULL
  )

if (print_large) {
  flowsom_speed_plot
}

flowsom_speed_plot %>% 
  ggsave(
    filename = 
      here::here(
        "manuscript", 
        "benchmarking", 
        str_replace(file_name, ".rds", ".pdf")
      ), 
    device = "pdf", 
    width = 5, 
    height = 3
  )

```


```{r extraction_file_name}
file_name <- 
  in_out_paths %>% 
  filter(process == "extraction") %>% 
  pull(file_name)
```


```{r visualize_extraction_result, message = FALSE}
extract_benchmarking <- 
  read_rds(file = here::here("manuscript", "benchmarking", file_name))

max_cells <- max(extract_benchmarking$num_cells)
width <- max_cells * 0.05
  

engines <- 
  extract_benchmarking %>% 
  select(extract_benchmarks) %>% 
  unnest(extract_benchmarks) %>% 
  pull(engine) %>% 
  unique()

num_engines <- length(engines)

my_palette <- charizard[which(names(charizard) %in% engines)]

extract_speed_plot <- 
  extract_benchmarking %>% 
  select(num_files, num_cells, extract_benchmarks) %>% 
  unnest(cols = extract_benchmarks) %>% 
  group_by(num_files, num_cells, engine) %>% 
  summarize(
    mean_time = median(time), 
    max_time = quantile(time, 0.75), 
    min_time = quantile(time, 0.25)
  ) %>% 
  ungroup() %>% 
  ggplot(
    aes(
      x = num_cells, 
      y = mean_time, 
      fill = engine, 
      color = engine, 
      ymin = min_time, 
      ymax = max_time
    )
  ) + 
  geom_errorbar(width = width) +
  geom_line(aes(group = engine)) +
  geom_point(shape = 21, size = 2, color = "black") + 
  scale_x_continuous(labels = scales::label_scientific(digits = 1)) + 
  scale_fill_manual(values = my_palette, labels = engine_labels) + 
  scale_color_manual(values = my_palette, labels = engine_labels) + 
  theme_bw() + 
  labs(
    subtitle = "Feature extraction",
    x = "Number of cells", 
    y = "Time (seconds)", 
    fill = NULL, 
    color = NULL
  )

if (print_large) {
  extract_speed_plot
}

extract_speed_plot %>% 
  ggsave(
    filename = 
      here::here(
        "manuscript", 
        "benchmarking", 
        str_replace(file_name, ".rds", ".pdf")
      ), 
    device = "pdf", 
    width = 5, 
    height = 3
  )

```


```{r visualize_lines_of_code}
code_tibble <- 
  read_rds(file = here::here("manuscript", "benchmarking", "code_style.rds"))

# visualize lines of code
engines <- 
  code_tibble %>% 
  pull(engine) %>% 
  unique()

my_palette <- charizard[names(charizard) %in% engines]

lines_plot_raw <- 
  code_tibble %>% 
  filter(measure == "lines") %>% 
  ggplot(aes(x = analysis, y = number, fill = engine)) + 
  geom_line(aes(group = engine, color = engine)) + 
  geom_point(shape = 21, size = 3) + 
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) + 
  scale_x_discrete(
    labels = 
      function(x) if_else(x %in% c("pca", "tsne", "umap"), str_to_upper(x), str_to_title(x))
  ) + 
  scale_fill_manual(values = my_palette, labels = engine_labels) + 
  scale_color_manual(values = my_palette, labels = engine_labels) + 
  labs(
    x = NULL, 
    y = "Lines of code", 
    fill = NULL, 
    color = NULL
  )

if (print_large) {
  lines_plot_raw
}
```


```{r save_raw_lines}
lines_plot_raw %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", "lines_plot_raw.pdf"), 
    device = "pdf", 
    width = 5, 
    height = 3.5
  )
```


```{r analyze_relative_lines_base}
# tibble with reduction column (percent reduction in lines of code in tidytof
# compared to whatever engine it's being compared to)
plot_tibble_base <- 
  code_tibble %>% 
  filter(engine %in% c("tidytof", "base")) %>% 
  filter(measure == "lines") %>% 
  group_by(analysis) %>% 
  mutate(
    lines = number, 
    number = number / max(number), 
    reduction = paste0(" (-", scales::label_percent()(1 - number), ")"), 
  ) %>% 
  ungroup()

lines_plot_base <- 
  plot_tibble_base %>% 
  ggplot(aes(x = analysis, y = number, fill = engine)) + 
  geom_segment(
    mapping = aes(x = analysis, y = 1, xend = analysis, yend = number + 0.04),
    data = filter(plot_tibble_base, engine == "tidytof"), 
    size = 1.5, 
    color = "gray60", 
    arrow = arrow(length = unit(0.1, "inches"), type = "closed"), 
    alpha = 0.9, 
    linejoin = "mitre", 
    lineend = "butt"
  ) + 
  geom_hline(yintercept = 1, size = 1, color = "black", linetype = "dotted") + 
  geom_point(shape = 21, size = 4) + 
  geom_text(
    mapping = aes(label = reduction), 
    data = filter(plot_tibble_base, engine == "tidytof"), 
    nudge_x = 0, 
    nudge_y = -0.12, 
    size = 3
  ) + 
  geom_text(
    aes(color = engine, label = paste0(lines, " lines")), 
    data = filter(plot_tibble_base, engine == "base"), 
    nudge_y = 0.06, 
    show.legend = FALSE, 
    size = 3
  ) + 
  geom_text(
    aes(color = engine, label = paste0(lines, if_else(lines == 1, " line", " lines"))), 
    data = filter(plot_tibble_base, engine == "tidytof"), 
    nudge_y = -0.06, 
    show.legend = FALSE, 
    size = 3
  ) + 
  scale_x_discrete(
    labels = 
      function(x) if_else(x %in% c("pca", "tsne"), str_to_upper(x), str_to_title(x))
  ) + 
  scale_y_continuous(labels = scales::label_percent()) + 
  scale_fill_manual(values = my_palette, labels = engine_labels) + 
  scale_color_manual(values = my_palette, labels = engine_labels) +
  theme_bw() + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.3)
  ) + 
  labs(
    x = NULL, 
    y = "Lines of code (% of base R)", 
    fill = NULL, 
    color = NULL
  )

if (print_large) {
  lines_plot_base
}

```

```{r analyze_relative_lines_flowcore}
# tibble with reduction column (percent reduction in lines of code in tidytof
# compared to whatever engine it's being compared to)
plot_tibble_flowcore <- 
  code_tibble %>% 
  filter(engine %in% c("tidytof", "flowcore")) %>% 
  filter(measure == "lines") %>% 
  filter(!(analysis %in% c("clustering", "feature extraction"))) %>% 
  group_by(analysis) %>% 
  mutate(
    lines = number, 
    number = number / max(number), 
    reduction = paste0(" (-", scales::label_percent()(1 - number), ")"), 
  ) %>% 
  ungroup()

lines_plot_flowcore <- 
  plot_tibble_flowcore %>% 
  ggplot(aes(x = analysis, y = number, fill = engine)) + 
  geom_segment(
    mapping = aes(x = analysis, y = 1, xend = analysis, yend = number + 0.04),
    data = filter(plot_tibble_flowcore, engine == "tidytof"), 
    size = 1.5, 
    color = "gray60", 
    arrow = arrow(length = unit(0.1, "inches"), type = "closed"), 
    alpha = 0.9, 
    linejoin = "mitre", 
    lineend = "butt"
  ) + 
  geom_hline(yintercept = 1, size = 1, color = "black", linetype = "dotted") + 
  geom_point(shape = 21, size = 4) + 
  geom_text(
    mapping = aes(label = reduction), 
    data = filter(plot_tibble_flowcore, engine == "tidytof"), 
    nudge_x = 0, 
    nudge_y = -0.12, 
    size = 3
  ) + 
  geom_text(
    aes(color = engine, label = paste0(lines, " lines")), 
    data = filter(plot_tibble_flowcore, engine == "flowcore"), 
    nudge_y = 0.06, 
    show.legend = FALSE, 
    size = 3
  ) + 
  geom_text(
    aes(color = engine, label = paste0(lines, if_else(lines == 1, " line", " lines"))), 
    data = filter(plot_tibble_flowcore, engine == "tidytof"), 
    nudge_y = -0.06, 
    show.legend = FALSE, 
    size = 3
  ) + 
  scale_x_discrete(
    labels = 
      function(x) if_else(x %in% c("pca", "tsne", "umap"), str_to_upper(x), str_to_title(x))
  ) + 
  scale_y_continuous(labels = scales::label_percent()) + 
  scale_fill_manual(values = my_palette, labels = engine_labels) + 
  scale_color_manual(values = my_palette, labels = engine_labels) +
  theme_bw() + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.3)
  ) + 
  labs(
    x = NULL, 
    y = "Lines of code (% of flowCore)", 
    fill = NULL, 
    color = NULL
  )

if (print_large) {
  lines_plot_flowcore
}

```

```{r}
# tibble with reduction column (percent reduction in lines of code in tidytof
# compared to whatever engine it's being compared to)
plot_tibble_cytofkit <- 
  code_tibble %>% 
  filter(engine %in% c("tidytof", "cytofkit")) %>% 
  filter(measure == "lines") %>% 
  group_by(analysis) %>% 
  mutate(
    lines = number, 
    number = number / max(number), 
    reduction = paste0(" (-", scales::label_percent()(1 - number), ")"), 
  ) %>% 
  ungroup() %>% 
  drop_na()

lines_plot_cytofkit <- 
  plot_tibble_cytofkit %>% 
  ggplot(aes(x = analysis, y = number, fill = engine)) + 
  geom_segment(
    mapping = aes(x = analysis, y = 1, xend = analysis, yend = number + 0.04),
    data = filter(plot_tibble_cytofkit, engine == "tidytof"), 
    size = 1.5, 
    color = "gray60", 
    arrow = arrow(length = unit(0.1, "inches"), type = "closed"), 
    alpha = 0.9, 
    linejoin = "mitre", 
    lineend = "butt"
  ) + 
  geom_hline(yintercept = 1, size = 1, color = "black", linetype = "dotted") + 
  geom_point(shape = 21, size = 4) + 
  geom_text(
    mapping = aes(label = reduction), 
    data = filter(plot_tibble_cytofkit, engine == "tidytof"), 
    nudge_x = 0, 
    nudge_y = -0.12, 
    size = 3
  ) + 
  geom_text(
    aes(color = engine, label = paste0(lines, " lines")), 
    data = filter(plot_tibble_cytofkit, engine == "cytofkit"), 
    nudge_y = 0.06, 
    show.legend = FALSE, 
    size = 3
  ) + 
  geom_text(
    aes(color = engine, label = paste0(lines, if_else(lines == 1, " line", " lines"))), 
    data = filter(plot_tibble_cytofkit, engine == "tidytof"), 
    nudge_y = -0.06, 
    show.legend = FALSE, 
    size = 3
  ) + 
  scale_x_discrete(
    labels = 
      function(x) if_else(x %in% c("pca", "tsne"), str_to_upper(x), str_to_title(x))
  ) + 
  scale_y_continuous(labels = scales::label_percent()) + 
  scale_fill_manual(values = my_palette, labels = engine_labels) + 
  scale_color_manual(values = my_palette, labels = engine_labels) +
  theme_bw() + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.3)
  ) + 
  labs(
    x = NULL, 
    y = "Lines of code (% of cytofkit)", 
    fill = NULL, 
    color = NULL
  )

if (print_large) {
  lines_plot_cytofkit
}
```



```{r save_relative_lines_plots}
lines_plot_base %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", "lines_plot_base.pdf"), 
    device = "pdf", 
    width = 6, 
    height = 4
  )

lines_plot_flowcore %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", "lines_plot_flowcore.pdf"), 
    device = "pdf", 
    width = 6, 
    height = 4
  )

lines_plot_cytofkit %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", "lines_plot_cytofkit.pdf"), 
    device = "pdf", 
    width = 6, 
    height = 4
  )
```

```{r analyze_raw_variables, message = FALSE, warning = FALSE}
variables_plot_raw <- 
  code_tibble %>% 
  filter(measure == "variables") %>% 
  ggplot(aes(x = analysis, y = number, fill = engine)) + 
  geom_line(aes(group = engine, color = engine)) + 
  geom_point(shape = 21, size = 3) + 
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) + 
  scale_x_discrete(
    labels = function(x) if_else(x %in% c("pca", "tsne", "umap"), str_to_upper(x), str_to_title(x))
  ) + 
  scale_fill_manual(values = my_palette) + 
  scale_color_manual(values = my_palette) + 
  labs(
    x = NULL, 
    y = "Assigned variables", 
    fill = NULL, 
    color = NULL
  )

if (print_large) {
  variables_plot_raw
}
```

```{r save_raw_variables}
variables_plot_raw %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", "variables_plot_raw.pdf"), 
    device = "pdf", 
    width = 4.5, 
    height = 3.5
  )
```



```{r analyze_relative_variables_base}
# tibble with reduction column (percent reduction in variable assignments in tidytof
# compared to whatever engine it's being compared to)
plot_tibble_base <- 
  code_tibble %>% 
  filter(engine %in% c("tidytof", "base")) %>% 
  filter(measure == "variables") %>% 
  group_by(analysis) %>% 
  mutate(
    lines = number, 
    number = number / max(number), 
    reduction = paste0(" (-", scales::label_percent()(1 - number), ")"), 
  ) %>% 
  ungroup()

variables_plot_base <- 
  plot_tibble_base %>% 
  ggplot(aes(x = analysis, y = number, fill = engine)) + 
  geom_segment(
    mapping = aes(x = analysis, y = 1, xend = analysis, yend = number + 0.04),
    data = filter(plot_tibble_base, engine == "tidytof"), 
    size = 1.5, 
    color = "gray60", 
    arrow = arrow(length = unit(0.1, "inches"), type = "closed"), 
    alpha = 0.9, 
    linejoin = "mitre", 
    lineend = "butt"
  ) + 
  geom_hline(yintercept = 1, size = 1, color = "black", linetype = "dotted") + 
  geom_point(shape = 21, size = 4) + 
  geom_text(
    mapping = aes(label = reduction), 
    data = filter(plot_tibble_base, engine == "tidytof"), 
    nudge_x = 0, 
    nudge_y = -0.12, 
    size = 3
  ) + 
  geom_text(
    aes(color = engine, label = paste0(lines, " vars")), 
    data = filter(plot_tibble_base, engine == "base"), 
    nudge_y = 0.06, 
    show.legend = FALSE, 
    size = 3
  ) + 
  geom_text(
    aes(color = engine, label = paste0(lines, if_else(lines == 1, " var", " vars"))), 
    data = filter(plot_tibble_base, engine == "tidytof"), 
    nudge_y = -0.06, 
    show.legend = FALSE, 
    size = 3
  ) + 
  scale_x_discrete(
    labels = 
      function(x) if_else(x %in% c("pca", "tsne", "umap"), str_to_upper(x), str_to_title(x))
  ) + 
  scale_y_continuous(labels = scales::label_percent()) + 
  scale_fill_manual(values = my_palette, labels = engine_labels) + 
  scale_color_manual(values = my_palette, labels = engine_labels) +
  theme_bw() + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.3)
  ) + 
  labs(
    x = NULL, 
    y = "Assigned variables (% of base R)", 
    fill = NULL, 
    color = NULL
  )

if (print_large) {
  variables_plot_base
}

```

```{r analyze_relative_variables_flowcore}
# tibble with reduction column (percent reduction in variable assignments in tidytof
# compared to whatever engine it's being compared to)
plot_tibble_flowcore <- 
  code_tibble %>% 
  filter(engine %in% c("tidytof", "flowcore")) %>% 
  filter(measure == "variables") %>% 
  filter(!(analysis %in% c("clustering", "feature extraction"))) %>% 
  group_by(analysis) %>% 
  mutate(
    lines = number, 
    number = number / max(number), 
    reduction = paste0(" (-", scales::label_percent()(1 - number), ")"), 
  ) %>% 
  ungroup()

variables_plot_flowcore <- 
  plot_tibble_flowcore %>% 
  ggplot(aes(x = analysis, y = number, fill = engine)) + 
  geom_segment(
    mapping = aes(x = analysis, y = 1, xend = analysis, yend = number + 0.04),
    data = filter(plot_tibble_flowcore, engine == "tidytof"), 
    size = 1.5, 
    color = "gray60", 
    arrow = arrow(length = unit(0.1, "inches"), type = "closed"), 
    alpha = 0.9, 
    linejoin = "mitre", 
    lineend = "butt"
  ) + 
  geom_hline(yintercept = 1, size = 1, color = "black", linetype = "dotted") + 
  geom_point(shape = 21, size = 4) + 
  geom_text(
    mapping = aes(label = reduction), 
    data = filter(plot_tibble_flowcore, engine == "tidytof"), 
    nudge_x = 0, 
    nudge_y = -0.12, 
    size = 3
  ) + 
  geom_text(
    aes(color = engine, label = paste0(lines, " vars")), 
    data = filter(plot_tibble_flowcore, engine == "flowcore"), 
    nudge_y = 0.06, 
    show.legend = FALSE, 
    size = 3
  ) + 
  geom_text(
    aes(color = engine, label = paste0(lines, if_else(lines == 1, " var", " vars"))), 
    data = filter(plot_tibble_flowcore, engine == "tidytof"), 
    nudge_y = -0.06, 
    show.legend = FALSE, 
    size = 3
  ) + 
  scale_x_discrete(
    labels = 
      function(x) if_else(x %in% c("pca", "tsne", "umap"), str_to_upper(x), str_to_title(x))
  ) + 
  scale_y_continuous(labels = scales::label_percent()) + 
  scale_fill_manual(values = my_palette, labels = engine_labels) + 
  scale_color_manual(values = my_palette, labels = engine_labels) +
  theme_bw() + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.3)
  ) + 
  labs(
    x = NULL, 
    y = "Assigned variables (% of flowCore)", 
    fill = NULL, 
    color = NULL
  )

if (print_large) {
  variables_plot_flowcore
}
```


```{r analyze_relative_variables_cytofkit}
# tibble with reduction column (percent reduction in variable assignments in tidytof
# compared to whatever engine it's being compared to)
plot_tibble_cytofkit <- 
  code_tibble %>% 
  filter(engine %in% c("tidytof", "cytofkit")) %>% 
  filter(measure == "variables") %>% 
  group_by(analysis) %>% 
  mutate(
    lines = number, 
    number = number / max(number), 
    reduction = paste0(" (-", scales::label_percent()(1 - number), ")"), 
  ) %>% 
  ungroup() %>% 
  drop_na()

variables_plot_cytofkit <- 
  plot_tibble_cytofkit %>% 
  ggplot(aes(x = analysis, y = number, fill = engine)) + 
  geom_segment(
    mapping = aes(x = analysis, y = 1, xend = analysis, yend = number + 0.04),
    data = filter(plot_tibble_cytofkit, engine == "tidytof"), 
    size = 1.5, 
    color = "gray60", 
    arrow = arrow(length = unit(0.1, "inches"), type = "closed"), 
    alpha = 0.9, 
    linejoin = "mitre", 
    lineend = "butt"
  ) + 
  geom_hline(yintercept = 1, size = 1, color = "black", linetype = "dotted") + 
  geom_point(shape = 21, size = 4) + 
  geom_text(
    mapping = aes(label = reduction), 
    data = filter(plot_tibble_cytofkit, engine == "tidytof"), 
    nudge_x = 0, 
    nudge_y = -0.12, 
    size = 3
  ) + 
  geom_text(
    aes(color = engine, label = paste0(lines, " vars")), 
    data = filter(plot_tibble_cytofkit, engine == "cytofkit"), 
    nudge_y = 0.06, 
    show.legend = FALSE, 
    size = 3
  ) + 
  geom_text(
    aes(color = engine, label = paste0(lines, if_else(lines == 1, " var", " vars"))), 
    data = filter(plot_tibble_cytofkit, engine == "tidytof"), 
    nudge_y = -0.06, 
    show.legend = FALSE, 
    size = 3
  ) + 
  scale_x_discrete(
    labels = 
      function(x) if_else(x %in% c("pca", "tsne", "umap"), str_to_upper(x), str_to_title(x))
  ) + 
  scale_y_continuous(labels = scales::label_percent()) + 
  scale_fill_manual(values = my_palette, labels = engine_labels) + 
  scale_color_manual(values = my_palette, labels = engine_labels) +
  theme_bw() + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.3)
  ) + 
  labs(
    x = NULL, 
    y = "Assigned variables (% of cytofkit)", 
    fill = NULL, 
    color = NULL
  )

if (print_large) {
  variables_plot_cytofkit
}

```


```{r save_relative_variables_plots}
variables_plot_base %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", "variables_plot_base.pdf"), 
    device = "pdf", 
    width = 8, 
    height = 5
  )

variables_plot_flowcore %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", "variables_plot_flowcore.pdf"), 
    device = "pdf", 
    width = 6.5, 
    height = 5
  )

variables_plot_cytofkit %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", "variables_plot_cytofkit.pdf"), 
    device = "pdf", 
    width = 6.5, 
    height = 5
  )
```





```{r visualize_memory_results}
average_mem_ratio <- 
  read_rds(file = here::here("manuscript", "benchmarking", "memory.rds")) %>% 
  mutate(mem_ratio = tidytof_memory / flowcore_memory) %>% 
  summarize(mem_ratio = mean(mem_ratio)) %>% 
  pull(mem_ratio)

memory_tibble <- 
  read_rds(file = here::here("manuscript", "benchmarking", "memory.rds")) %>% 
  pivot_longer(
    cols = contains("_memory"), 
    names_to = "engine", 
    values_to = "memory"
  ) %>% 
  mutate(engine = str_remove(engine, "_memory"))

engines <- 
  memory_tibble %>% 
  pull(engine) %>% 
  unique()

my_palette <- charizard[which(names(charizard) %in% engines)]

memory_plot <- 
  memory_tibble %>% 
  ggplot(aes(x = num_cells, y = memory, fill = engine, color = engine)) + 
  geom_line() +
  geom_point(shape = 21, size = 2, color = "black") + 
  scale_x_continuous(labels = scales::label_scientific(digits = 1)) + 
  scale_fill_manual(values = my_palette, labels = engine_labels) + 
  scale_color_manual(values = my_palette, labels = engine_labels) +
  theme_bw() + 
  labs(
    subtitle = "Dataset memory requirements",
    x = "Number of cells", 
    y = "Memory (MB)", 
    fill = NULL, 
    color = NULL
  )

memory_plot %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", "memory_plot.png"), 
    device = "png", 
    width = 5, 
    height = 3
  )

if (print_large) { 
  memory_plot
}


memory_plot %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", "memory_plot.pdf"), 
    device = "pdf", 
    width = 5, 
    height = 3
  )
  
```

## Methods

```{r}
ddpr_data_info <-
  read_rds(
    file = here::here("manuscript", "benchmarking", "ddpr_data_info.rds")
  )

largest_cohort_names <-
  ddpr_data_info %>%
  filter(num_files == 288L) %>%
  pull(file_names) %>%
  pluck(1)

all_file_names <-
  largest_cohort_names[1:20]

smallest_num_cells <- 
  memory_tibble %>% 
  pull(num_cells) %>% 
  min()

total_num_cells <- 
  memory_tibble %>% 
  pull(num_cells) %>% 
  max()

```


To benchmark {tidytof}'s performance against existing tools for high-dimensional cytometry data analysis, we compared {tidytof} functions to their equivalent workflows (where they existed) using base R @baseR or the {flowCore} package @flowcore. Workflows were compared both on the basis of their computational speed on datasets of various sizes (see below for details) and on the basis of their coding burden (i.e. the amount of code needed for each workflow). Specifically, comparisons included one metric for computational speed (total elapsed time for each workflow) and two metrics for coding burden associated with human error when conducting computational analyses (the number of lines of code and the number of intermediate variable assignments needed for the workflow). In addition, {tidytof}'s memory requirements were benchmarked against those of the {flowCore} package's `flowSet` objects, a commonly-used data structure for the analysis of high-dimensional cytometry data. 

All benchmarking was performed on a Linux machine running Ubuntu 20.04 with an AMD Threadripper Pro 3995WX processor (64 cores; 2.70 GHz; 256 MB cache) and 256 GB of RAM. All functions used to perform speed, coding burden, and memory benchmarking are available [here](https://github.com/keyes-timothy/tidytof/blob/main/manuscript/benchmarking/benchmarking_functions.R).


### Benchmarking datasets

The data used for benchmarking were drawn from Good et al.'s publicly available CyTOF dataset published in 2018 @ddpr. Specifically, 20 files acquired from 2 healthy patients were chosen from the full dataset, totaling `r total_num_cells` cells. The following files were used: 

```{r, results = "asis"}
brdr <- officer::fp_border(color = "black", width = 0.5)

tibble(`File name` = all_file_names) %>% 
  flextable::flextable() %>% 
  flextable::bold(i = 1, part = "header") %>% 
  flextable::fontsize(part = "all", size = 10) %>% 
  #flextable::padding(padding = 0, part = "all") %>% 
  #flextable::line_spacing(part = "all", space = 1) %>% 
  flextable::hline_top(part = "header", border = brdr) %>% 
  flextable::hline_bottom(part = "header", border = brdr) %>% 
  flextable::hline_bottom(part = "body", border = brdr) %>% 
  flextable::autofit() %>% 
  flextable::flextable_to_rmd(ft.arraystretch = 1.1)
```

### Speed benchmarking

For speed benchmarking, each workflow was run on 20 nested datasets derived from the files listed above such that each dataset *i* was comprised of the first *i* files in the list. Thus, the smallest dataset included only 1 file (and `r smallest_num_cells` cells) while the largest dataset included all 20 files (and `r total_num_cells` cells). However, due to the computationally intensive nature of t-stochastic neighborhood embedding (tSNE) and uniform manifold approximation and projection (UMAP), speed benchmarking was performed using 10 subsampled versions of the full dataset (all 20 files) with a smaller number of cells drawn at random: 1K, 2K, 3K, 4K, 5K, 6K, 7K, 8K, 9K, and 10K.

Using these datasets, the `microbenchmark` package @microbenchmark was used to time each workflow independently on each dataset 10 times. The median and interquartile range of each workflow's runtime could then be computed for {tidytof}, base R, and {flowCore}. For dimensionality reduction and clustering analyses, only cluster of differentiation ("CD") markers were used for analysis across all workflows. For downsampling, 200 cells were subsampled from each input FCS or CSV file. Otherwise, {tidytof}'s default behavior was used across all functions used for speed benchmarking.

### Memory benchmarking

For memory benchmarking, each nested dataset described above was read into both a `tof_tbl` object using {tidytof}'s `tof_read_data()` function and a `flowSet` object using {flowCore}'s `read.flowSet()` function. The system memory used to store each object was calculated using the {lobstr} package's `obj_size()` function @lobstr. 

### Coding burden benchmarking

For coding burden benchmarking, the source code of the functions containing each workflow was subjected to text analysis. To control for differences in code style and practices between workflows, the {styler} package @styler was used to standardize all benchmarking code to adhere to the [tidyverse R code style guide](https://style.tidyverse.org/). The functions used to count the number of lines of code and the number of variable assignments in each workflow are provided here:


```{r, echo = TRUE, include = TRUE, eval = FALSE}
# count the lines of code for a given workflow
get_lines <- function(function_object) { 
  if (is.na(function_object)) {
    return(NA)
  } else {
    lines <- capture.output(print(function_object))
    # substract 2 lines to omit the function definition and closing 
    # bracket for each workflow
    return(length(lines) - 2L)
  }
}

# count the number of assigned variables for a given workflow
get_assignments <- function(function_object) {
  if (is.na(function_object)) {
    return(NA)
  } else {
    lines <- capture.output(print(function_object))
    assignments <- max(sum(str_count(lines, pattern = "<-")), 1L)
    return(assignments)
  }
}
```

For both functions above, the input is a function (`function_object`) used to define a {tidytof}, base R, or {flowCore} analysis workflow, and the output is an integer representing the number of lines of code or the number of variable assignments, respectively, contained in the workflow. The functions used to define each workflow are available on GitHub [here](https://github.com/keyes-timothy/tidytof/blob/main/manuscript/benchmarking/benchmarking_functions.R). 

## Results 

### Speed benchmarking

Across a wide variety of workflows including FCS and CSV file reading, single-cell data transformation (preprocessing), downsampling, tSNE embedding, FlowSOM clustering, and sample-level feature extraction, 
{tidytof}'s time efficiency rivals or improves upon alternative approaches (**Supplementary Figure 1**). In the case of PCA and UMAP, {tidytof} incurs a slight performance decrease relative to alternative tools because it uses the `{embed}` package @embed to store a dataset's PCA or UMAP embedding as a `recipe` object (from the {recipes} package) @recipes - which, while costing a small amount of computational overhead, allows users to more easily apply the same embedding to new data points. 

\newpage

```{r, message = FALSE}
make_speed_plots <- 
  function(speed_plot_list) { 
    speed_plot_list <- 
      map(
        .x = speed_plot_list, 
        .f = ~ .x + 
          scale_fill_manual(values = charizard, labels = engine_labels) + 
          scale_color_manual(values = charizard, labels = engine_labels) + 
          scale_x_continuous(
            breaks = scales::breaks_pretty(n = 4), 
            labels = scales::label_scientific()
          )
      )
    result <- 
      speed_plot_list %>% 
      wrap_plots() + 
      plot_layout(ncol = 3, guides = "collect") + 
      plot_annotation(tag_levels = "A") + 
      theme(plot.tag = element_text(face = "bold"))
    return(result)
  }
```

```{r, fig.width = 10, fig.height = 8, warning = FALSE, message = FALSE}
all_speed_names <- 
  ls()[str_detect(string = ls(), pattern = "speed_plot(_csv)?$")] %>% 
  factor(levels = 
           c("io_speed_plot", "io_speed_plot_csv", "preprocess_speed_plot",
             "downsample_speed_plot", "pca_speed_plot", "tsne_speed_plot", 
             "umap_speed_plot", "flowsom_speed_plot", "extract_speed_plot")
  ) %>% 
  sort() %>% 
  as.character()

all_speed_plots <- 
  all_speed_names %>% 
  mget(envir = globalenv()) %>% 
  make_speed_plots()

all_speed_plots

all_speed_plots %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", "all_speed_plots.png"), 
    device = "png", 
    width = 10, 
    height = 8
  )


all_speed_plots %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", "all_speed_plots.pdf"), 
    device = "pdf", 
    width = 10, 
    height = 8
  )
```
**Supplementary Figure 1 - {tidytof}'s computational speed rivals or improves upon equivalent approaches in base R or {flowCore}.** Benchmark plots indicating the elapsed time for (A) reading FCS files, (B) reading CSV files, (C) preprocessing single-cell data, (D) downsampling single-cell data, (E) performing principal component analysis (PCA), (F) performing t-stochastic neighborhood embedding (tSNE), (G) performing uniform manifold approximation and projection (UMAP) embedding), (H) performing FlowSOM clustering, (I) or sample-level feature extraction using {tidytof}, base R, and {flowCore}. Points represent the median runtime for each workflow from 10 independent repetitions; error bars represent the interquartile range of runtimes.

\newpage 

### Memory benchmarking

```{r}
average_increase <- 
  ((average_mem_ratio - 1) * 100) %>% 
  round(2) %>% 
  str_c("%")

```


Despite the increased simplicity of {tidytof}'s tidy data structures (`tof_tbl` objects) compared to {flowCore}'s native data structure (the `flowSet`), both data structures require similar amounts of system memory (**Supplementary Figure 2**). Across all datasets, {tidytof} data structures require slightly more memory on average than their {flowCore} counterparts, with an average increase of `r average_increase` across all datasets. 

\


```{r}
memory_plot + 
  scale_x_continuous(breaks = scales::breaks_extended(n = 5), labels = scales::label_scientific())
```


**Supplementary Figure 2 - {tidytof}'s tidy data structures require similar system memory to {flowCore} flowSet objects.** The system memory (in Megabytes; MB) required to store {tidytof} and {flowCore} data structures of varying sizes. 


\newpage 

### Coding burden benchmarking

In addition to its competitive computational speed relative to equivalent base R and {flowCore} workflows, {tidytof} reduces the coding burden of performing CyTOF data analyses significantly compared to alternative frameworks. Across workflows, {tidytof} reduces the lines of code needed to perform an analysis between 70% and 95% compared to base R and between 56% and 96% compared to {flowCore} (**Supplementary Figure 3**). Similarly, {tidytof} reduces the number of variable assignments needed to perform an analysis between 75% to 97% compared to base R and between 75% and 95% compared to {flowCore} (**Supplementary Figure 4**). Because code bases with both more lines of code and more intermediate variables are more prone to human (e.g copy-and-paste) error and reduced readability, these results support {tidytof}'s marked ability to simplify CyTOF data analysis code and increase reproducibility among data analysis pipelines.

\ 

\ 

```{r}
make_style_plot <- function(raw, base, flowcore, cytofkit) { 
  base <- base + theme(legend.position = "none")
  flowcore <- flowcore + theme(legend.position = "none")
  cytofkit <- cytofkit + theme(legend.position = "none")
  
  result <- 
    raw +
    (base + 
       flowcore + 
       plot_layout(nrow = 1, widths = c(5.8, 4.2))
    ) + 
    cytofkit +
    plot_layout(
      guides = "collect", 
      heights = c(4, 6, 6),
      design = "
      #1111#
      222222
      333###
    "
    ) + 
    plot_annotation(tag_levels = "A") + 
    theme(plot.tag = element_text(face = "bold"))
  return(result)
}


```


```{r, fig.width = 10, fig.height = 10}
lines_patchwork <- 
  make_style_plot(
    raw = lines_plot_raw, 
    base = lines_plot_base, 
    flowcore = lines_plot_flowcore,
    cytofkit = lines_plot_cytofkit
  )

lines_patchwork


lines_patchwork %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", "lines_patchwork.png"), 
    device = "png", 
    width = 9.8, 
    height = 10
  )


lines_patchwork %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", "lines_patchwork.pdf"), 
    device = "pdf", 
    width = 9.8, 
    height = 10
  )
  
```


**Supplementary Figure 3 - {tidytof} coding style reduces the number of lines of code needed for CyTOF data analysis pipelines.** (A) Raw lines of code needed to perform equivalent analyses using {tidytof}, base R, and {flowCore}. (B) The relative (% of base R) lines of code needed to perform equivalent analyses using {tidytof} and base R. (C) The relative (% of {flowCore}) lines of code needed to perform equivalent analyses using {tidytof} and {flowCore}. Note that {flowCore} does not provide off-the-shelf tools for clustering or feature extraction, so these values are omitted in panels A-C.

\newpage 


```{r, fig.width = 9.5, fig.height = 10}
variables_patchwork <- 
  make_style_plot(
    raw = variables_plot_raw, 
    base = variables_plot_base, 
    flowcore = variables_plot_flowcore, 
    cytofkit = variables_plot_cytofkit
  )

print(variables_patchwork)

variables_patchwork %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", "variables_patchwork.png"), 
    device = "png", 
    width = 9.2, 
    height = 10
  )

variables_patchwork %>% 
  ggsave(
    filename = 
      here::here("manuscript", "benchmarking", "variables_patchwork.pdf"), 
    device = "pdf", 
    width = 9.2, 
    height = 10
  )
  
```


**Supplementary Figure 4 - {tidytof} coding style reduces the number of intermediate variable assignments needed in equivalent CyTOF data analyis pipelines.** (A) Raw number of variable assignments needed to perform equivalent analyses using {tidytof}, base R, and {flowCore}. (B) The relative (% of base R) number of variable assignments needed to perform equivalent analyses using {tidytof} and base R. (C) The relative (% of {flowCore}) number of variables assignments needed to perform equivalent analyses using {tidytof} and {flowCore}. Note that {flowCore} does not provide off-the-shelf tools for clustering or feature extraction, so these values are omitted in panels A-C.


